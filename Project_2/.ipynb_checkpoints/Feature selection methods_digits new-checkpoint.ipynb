{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_digits=pd.read_csv(\"data/digits_train.data\",header=None, sep=\" \")\n",
    "\n",
    "x_train_digits=x_train_digits.drop(columns=[5000])\n",
    "\n",
    "y_train_digits=pd.read_csv(\"data/digits_train.labels\",header=None, sep=\" \")\n",
    "\n",
    "y_train_digits=y_train_digits.to_numpy().reshape(-1)\n",
    "\n",
    "x_val_digits=pd.read_csv(\"data/digits_valid.data\",header=None, sep=\" \").iloc[:,:5000]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train_digits)\n",
    "x_train=scaler.transform(x_train_digits)\n",
    "x_val=scaler.transform(x_val_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=pd.read_csv(\"MATSZY_digits_features.txt\").MATSZY.to_numpy()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=x_val[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train_pca=pca.transform(x_train)\n",
    "x_val_pca=pca.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier().fit(x_train_pca, y_train_digits)\n",
    "\n",
    "pred = forest.predict(x_train_pca)\n",
    "\n",
    "balanced_accuracy_score(y_train_digits, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest:  [0.9724619553887847, 0.9716765189563981, 0.9596318383604624, 0.9625182304326689, 0.9629164993978322]\n",
      "Logistic regression:  [0.9572441109026475, 0.9583537046090937, 0.9485697437666196, 0.9574623237724842, 0.9531647263481868]\n"
     ]
    }
   ],
   "source": [
    "acc_reg=[0 for x in range(5)]\n",
    "acc_forest=[0 for x in range(5)]\n",
    "for i in range(5):\n",
    "    mask = np.zeros(x_train_pca.shape[0], dtype=bool)\n",
    "    mask[i::5] = True\n",
    "\n",
    "    x_test = x_train_pca[mask]\n",
    "    x_fold = x_train_pca[~mask]\n",
    "    \n",
    "    y_test = y_train_digits[mask]\n",
    "    y_fold = y_train_digits[~mask]\n",
    "    \n",
    "    reg = LogisticRegression().fit(x_fold, y_fold)\n",
    "    pred = reg.predict(x_test)\n",
    "    acc_reg[i]=balanced_accuracy_score(y_test, pred)\n",
    "    \n",
    "    forest=RandomForestClassifier().fit(x_fold, y_fold)\n",
    "    pred = forest.predict(x_test)\n",
    "    acc_forest[i]=balanced_accuracy_score(y_test, pred)\n",
    "print('Forest: ', acc_forest)\n",
    "print('Logistic regression: ', acc_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658410085072292"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc_forest)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier().fit(x_train_pca, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56, 0.95, 0.12, 0.96, 0.92, 0.06, 0.02, 0.05, 0.01, 0.03, 0.98,\n",
       "       0.82, 0.24, 0.94, 0.33, 0.82, 0.96, 0.9 , 0.95, 1.  , 0.1 , 0.95,\n",
       "       0.77, 0.75, 0.87, 0.07, 0.97, 0.99, 0.37, 0.73, 0.8 , 0.57, 0.21,\n",
       "       0.98, 0.53, 0.98, 0.49, 1.  , 0.22, 0.2 , 0.98, 0.06, 0.82, 0.97,\n",
       "       0.17, 0.22, 0.9 , 0.3 , 0.84, 0.15, 0.42, 0.02, 0.02, 0.02, 0.87,\n",
       "       0.98, 0.32, 0.04, 0.51, 0.94, 0.94, 0.02, 0.07, 0.9 , 0.31, 0.12,\n",
       "       1.  , 0.97, 0.9 , 0.89, 0.34, 0.27, 0.41, 1.  , 0.89, 0.9 , 0.35,\n",
       "       0.08, 0.98, 0.98, 0.25, 0.99, 0.58, 0.79, 0.4 , 0.91, 0.21, 0.98,\n",
       "       0.37, 0.7 , 0.84, 0.44, 0.25, 0.04, 0.97, 0.12, 0.98, 0.14, 0.56,\n",
       "       0.99, 0.05, 0.19, 0.65, 0.94, 0.99, 0.82, 0.04, 0.95, 0.94, 0.03,\n",
       "       0.71, 0.16, 0.54, 0.2 , 0.82, 0.98, 0.03, 0.  , 0.31, 0.78, 0.03,\n",
       "       0.99, 0.17, 0.64, 0.19, 0.15, 0.98, 0.11, 0.04, 0.22, 0.21, 0.21,\n",
       "       0.1 , 0.46, 0.05, 0.89, 0.9 , 0.98, 0.06, 0.86, 0.89, 0.9 , 0.07,\n",
       "       0.96, 0.82, 0.8 , 0.04, 0.95, 0.78, 0.02, 0.93, 0.07, 0.85, 0.73,\n",
       "       0.8 , 0.08, 0.92, 0.07, 0.94, 0.15, 0.99, 0.03, 0.75, 0.14, 0.56,\n",
       "       0.03, 0.24, 0.03, 0.98, 1.  , 0.77, 0.73, 0.08, 0.46, 0.92, 0.95,\n",
       "       0.83, 0.68, 0.89, 0.05, 0.12, 0.76, 0.1 , 0.16, 0.15, 0.91, 0.68,\n",
       "       0.9 , 0.86, 0.34, 0.93, 0.66, 0.98, 0.04, 0.91, 0.22, 0.04, 0.02,\n",
       "       0.93, 0.95, 0.79, 0.97, 0.06, 0.82, 0.28, 0.24, 0.99, 0.01, 0.93,\n",
       "       0.35, 0.84, 0.11, 0.99, 0.93, 0.08, 0.2 , 0.66, 0.04, 0.97, 0.23,\n",
       "       0.79, 0.58, 0.11, 0.9 , 0.15, 0.11, 0.96, 0.63, 0.19, 0.39, 0.04,\n",
       "       0.11, 0.92, 0.02, 0.08, 0.26, 0.21, 0.82, 0.17, 0.73, 0.91, 0.64,\n",
       "       0.04, 0.03, 0.07, 0.65, 0.49, 0.46, 0.91, 0.96, 0.85, 1.  , 0.98,\n",
       "       0.16, 0.89, 0.05, 0.9 , 0.72, 0.18, 0.98, 0.95, 0.35, 0.12, 0.58,\n",
       "       0.06, 0.92, 0.09, 0.92, 0.89, 0.45, 0.17, 0.04, 0.7 , 0.75, 0.03,\n",
       "       0.06, 0.23, 0.9 , 0.98, 0.83, 0.99, 0.91, 0.12, 0.94, 0.13, 0.15,\n",
       "       0.49, 0.77, 0.13, 0.89, 0.04, 0.11, 0.58, 0.84, 0.08, 0.86, 0.86,\n",
       "       0.51, 0.98, 0.19, 0.78, 0.99, 0.36, 0.13, 0.09, 0.2 , 0.19, 0.72,\n",
       "       0.37, 0.63, 0.99, 0.98, 0.03, 0.04, 0.6 , 0.99, 0.04, 0.04, 0.99,\n",
       "       0.14, 0.05, 0.27, 0.85, 0.16, 0.67, 0.03, 0.51, 0.96, 0.34, 0.4 ,\n",
       "       0.69, 0.21, 0.04, 0.74, 0.15, 0.96, 0.89, 0.45, 0.72, 0.99, 0.85,\n",
       "       0.99, 0.45, 0.2 , 0.04, 0.64, 0.98, 0.91, 0.96, 0.16, 0.63, 0.14,\n",
       "       0.69, 0.08, 0.13, 0.24, 0.93, 0.97, 0.82, 0.2 , 0.89, 0.96, 0.92,\n",
       "       0.28, 0.81, 0.05, 0.39, 0.95, 0.09, 0.77, 0.21, 0.19, 0.83, 0.67,\n",
       "       0.13, 0.14, 0.05, 0.92, 0.99, 0.12, 0.86, 0.98, 0.96, 0.2 , 0.74,\n",
       "       0.1 , 0.23, 0.49, 0.82, 0.33, 0.13, 0.96, 0.85, 0.07, 0.08, 0.22,\n",
       "       1.  , 0.09, 0.81, 0.9 , 0.82, 0.93, 0.06, 0.86, 0.92, 0.13, 0.01,\n",
       "       0.33, 0.14, 0.38, 0.01, 0.86, 0.13, 0.01, 0.59, 0.97, 0.67, 0.13,\n",
       "       0.1 , 0.08, 0.93, 0.84, 0.97, 0.14, 0.94, 0.06, 0.99, 1.  , 0.1 ,\n",
       "       0.49, 0.69, 0.08, 0.06, 0.8 , 0.11, 0.83, 0.95, 0.93, 0.96, 0.87,\n",
       "       0.07, 0.31, 0.07, 0.88, 0.99, 0.8 , 0.67, 0.03, 0.08, 0.  , 0.36,\n",
       "       0.88, 0.08, 0.91, 0.37, 0.52, 0.21, 0.03, 0.95, 0.13, 0.07, 0.84,\n",
       "       0.33, 0.1 , 0.72, 0.93, 0.96, 0.12, 0.77, 0.05, 0.86, 0.07, 0.17,\n",
       "       0.82, 0.96, 0.84, 0.9 , 0.16, 0.04, 0.9 , 0.89, 0.94, 0.48, 0.02,\n",
       "       0.99, 0.88, 0.1 , 0.6 , 0.95, 0.03, 0.04, 0.45, 0.66, 0.04, 0.08,\n",
       "       0.91, 0.7 , 0.79, 0.94, 0.16, 0.7 , 0.88, 0.06, 0.02, 0.36, 0.18,\n",
       "       0.03, 0.51, 0.24, 0.83, 0.28, 0.88, 0.72, 0.22, 0.04, 0.07, 0.35,\n",
       "       0.1 , 0.06, 0.22, 0.31, 0.04, 0.64, 0.88, 0.67, 0.1 , 0.42, 0.94,\n",
       "       0.61, 0.89, 0.52, 0.18, 0.88, 0.29, 0.6 , 0.91, 0.39, 0.89, 0.06,\n",
       "       0.79, 0.3 , 0.89, 0.06, 0.07, 0.17, 0.12, 0.82, 0.99, 0.92, 0.79,\n",
       "       0.92, 0.02, 0.02, 0.07, 0.9 , 0.19, 0.95, 0.88, 0.07, 0.92, 0.89,\n",
       "       0.96, 0.93, 0.02, 0.04, 0.75, 0.04, 0.06, 0.15, 0.06, 0.79, 0.87,\n",
       "       0.13, 0.9 , 0.96, 0.13, 0.93, 0.67, 0.9 , 0.08, 0.04, 0.08, 0.15,\n",
       "       0.3 , 0.7 , 0.15, 0.32, 0.13, 0.91, 0.94, 1.  , 0.32, 0.2 , 0.13,\n",
       "       0.04, 0.84, 0.14, 0.94, 0.9 , 0.1 , 0.54, 0.87, 0.06, 0.6 , 0.02,\n",
       "       0.09, 0.02, 0.39, 0.98, 0.95, 0.42, 0.89, 0.99, 0.04, 0.8 , 0.04,\n",
       "       0.1 , 0.28, 0.17, 0.44, 0.1 , 0.5 , 0.08, 0.32, 0.88, 0.84, 0.94,\n",
       "       0.06, 0.24, 0.19, 0.21, 0.96, 0.74, 0.16, 0.98, 0.89, 0.11, 0.89,\n",
       "       0.92, 0.83, 0.38, 0.98, 0.24, 0.36, 0.52, 0.06, 0.1 , 0.66, 0.08,\n",
       "       0.97, 0.07, 0.15, 0.23, 0.86, 0.07, 0.08, 0.33, 0.25, 0.03, 0.77,\n",
       "       0.93, 0.94, 0.84, 0.25, 0.28, 0.18, 0.97, 0.09, 0.25, 1.  , 0.12,\n",
       "       0.43, 0.89, 0.73, 0.08, 0.01, 0.33, 0.95, 0.21, 0.74, 0.1 , 0.91,\n",
       "       0.19, 0.99, 0.85, 0.04, 0.8 , 0.27, 0.98, 0.79, 0.94, 0.03, 0.96,\n",
       "       0.91, 0.13, 0.06, 0.05, 0.05, 0.88, 0.15, 0.92, 0.07, 0.04, 0.97,\n",
       "       0.09, 0.19, 0.73, 0.9 , 0.09, 0.19, 0.86, 0.97, 0.22, 0.14, 0.98,\n",
       "       0.14, 0.21, 0.02, 0.22, 0.95, 0.94, 0.95, 0.97, 0.9 , 0.83, 0.72,\n",
       "       0.19, 0.24, 0.99, 0.12, 0.89, 0.74, 0.98, 0.65, 0.03, 0.33, 0.16,\n",
       "       0.95, 0.8 , 0.88, 0.05, 0.04, 0.25, 0.21, 0.91, 0.25, 0.84, 0.04,\n",
       "       0.91, 0.03, 0.5 , 0.9 , 0.05, 0.9 , 0.06, 0.73, 0.85, 0.11, 0.89,\n",
       "       0.83, 0.71, 0.38, 0.95, 0.25, 0.95, 0.88, 0.09, 0.96, 0.07, 0.55,\n",
       "       0.12, 0.05, 0.75, 0.99, 0.13, 0.89, 0.05, 0.76, 0.99, 0.08, 0.07,\n",
       "       0.23, 0.39, 0.17, 0.13, 0.82, 0.05, 0.19, 0.09, 0.12, 0.05, 0.05,\n",
       "       0.85, 0.05, 0.93, 0.09, 0.8 , 0.79, 0.03, 0.84, 0.48, 0.94, 0.03,\n",
       "       0.2 , 0.09, 0.81, 0.95, 0.77, 0.16, 0.12, 0.16, 0.96, 0.28, 0.96,\n",
       "       0.85, 0.89, 0.14, 0.04, 0.06, 0.95, 0.63, 0.71, 1.  , 0.79, 0.16,\n",
       "       0.07, 0.94, 0.18, 0.64, 0.94, 0.17, 0.97, 0.06, 0.56, 0.92, 0.91,\n",
       "       0.06, 0.05, 0.04, 0.93, 0.75, 0.34, 0.14, 0.86, 0.65, 0.78, 0.13,\n",
       "       0.05, 0.88, 0.08, 0.25, 0.01, 0.65, 0.03, 0.97, 0.06, 0.23, 0.75,\n",
       "       0.96, 0.93, 0.1 , 0.59, 0.05, 0.14, 0.06, 0.68, 0.78, 0.11, 0.94,\n",
       "       0.9 , 0.94, 0.03, 0.22, 0.91, 0.  , 0.76, 0.02, 0.07, 0.99, 0.36,\n",
       "       0.06, 0.09, 0.08, 0.83, 0.69, 0.68, 0.03, 0.85, 0.6 , 0.97, 0.03,\n",
       "       0.6 , 0.89, 0.78, 0.48, 0.6 , 0.84, 0.26, 0.34, 0.02, 0.02, 0.07,\n",
       "       0.05, 0.17, 0.97, 0.65, 0.08, 0.08, 0.82, 0.42, 0.65, 0.78, 0.59,\n",
       "       0.76, 0.04, 0.01, 0.15, 0.01, 0.98, 0.88, 0.79, 0.8 , 0.8 , 0.05,\n",
       "       0.93, 0.4 , 0.75, 0.13, 0.05, 0.14, 0.05, 0.05, 0.1 , 0.5 , 0.92,\n",
       "       0.13, 0.85, 0.74, 0.88, 0.09, 0.19, 0.49, 0.05, 0.95, 0.07, 0.85,\n",
       "       0.15, 0.82, 0.11, 0.97, 0.62, 0.76, 0.22, 0.04, 0.98, 0.88, 0.09,\n",
       "       0.84, 0.98, 0.84, 0.08, 0.9 , 0.08, 0.96, 0.88, 0.02, 0.83, 0.85,\n",
       "       0.92, 0.03, 0.28, 0.95, 0.46, 0.88, 0.05, 0.23, 0.09, 0.87, 0.62,\n",
       "       0.97, 0.79, 0.67, 0.2 , 0.74, 0.15, 0.11, 0.87, 0.97, 0.95, 0.17,\n",
       "       0.07, 0.92, 0.13, 0.88, 0.21, 0.08, 0.68, 0.78, 0.02, 0.04])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs = forest.predict_proba(x_val_pca)[:,1]\n",
    "posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'MATSZY': posterior_probs}).to_csv('MATSZY_digits_prediction.txt', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_kbest = np.where(kbest.get_support())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    6,    7, ..., 4994, 4997, 4999], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_indexes = vars_kbest[feat_selector_digits.support_]\n",
    "pd.DataFrame({'MATSZY': vars_indexes + 1}).to_csv('MATSZY_digits_features.txt', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
